#!/usr/bin/env python3
"""
ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°æ©Ÿèƒ½

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç›£è¦–ã—ã€
ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã€è©³ç´°ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import gc
import json
import logging
import os
import psutil
import sys
import threading
import time
import tracemalloc
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, Tuple
import subprocess

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)


@dataclass
class MemorySnapshot:
    """ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    timestamp: datetime
    process_memory_mb: float
    system_memory_percent: float
    tracemalloc_current_mb: float
    tracemalloc_peak_mb: float
    gc_objects_count: int
    thread_count: int
    file_descriptors: int
    context: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        return result


@dataclass
class MemoryLeak:
    """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºçµæœ"""
    start_snapshot: MemorySnapshot
    end_snapshot: MemorySnapshot
    leak_rate_mb_per_sec: float
    total_leaked_mb: float
    duration_seconds: float
    severity: str  # 'LOW', 'MEDIUM', 'HIGH', 'CRITICAL'
    analysis: str
    top_allocations: List[Dict[str, Any]]


@dataclass
class MemoryThresholds:
    """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡é–¾å€¤è¨­å®š"""
    process_memory_mb: float = 500.0  # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰
    system_memory_percent: float = 80.0  # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    leak_rate_mb_per_sec: float = 1.0  # ãƒªãƒ¼ã‚¯ç‡ï¼ˆMB/ç§’ï¼‰
    gc_objects_growth_rate: float = 1000.0  # GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¢—åŠ ç‡ï¼ˆå€‹/ç§’ï¼‰


class MemoryProfiler:
    """ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, data_dir: str = "logs/performance/memory"):
        """
        ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–

        Args:
            data_dir: ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.snapshots_file = self.data_dir / "memory_snapshots.json"
        self.leaks_file = self.data_dir / "memory_leaks.json"
        self.reports_dir = self.data_dir / "reports"
        self.reports_dir.mkdir(exist_ok=True)
        
        # ãƒ—ãƒ­ã‚»ã‚¹æƒ…å ±
        self.process = psutil.Process()
        
        # ç›£è¦–è¨­å®š
        self.thresholds = MemoryThresholds()
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        self.monitoring_interval = 5.0  # 5ç§’é–“éš”
        
        # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå±¥æ­´
        self.snapshots: List[MemorySnapshot] = []
        self.max_snapshots = 1000  # æœ€å¤§ä¿æŒã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°
        
        # tracemallocåˆæœŸåŒ–
        if not tracemalloc.is_tracing():
            tracemalloc.start()
            logger.info("tracemallocç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        logger.info("ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

    def take_snapshot(self, context: str = "") -> MemorySnapshot:
        """
        ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—

        Args:
            context: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±

        Returns:
            ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        """
        try:
            # ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªæƒ…å ±
            memory_info = self.process.memory_info()
            process_memory_mb = memory_info.rss / 1024 / 1024
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªæƒ…å ±
            system_memory = psutil.virtual_memory()
            system_memory_percent = system_memory.percent
            
            # tracemallocæƒ…å ±
            current_size, peak_size = tracemalloc.get_traced_memory()
            tracemalloc_current_mb = current_size / 1024 / 1024
            tracemalloc_peak_mb = peak_size / 1024 / 1024
            
            # GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°
            gc_objects_count = len(gc.get_objects())
            
            # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
            thread_count = threading.active_count()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿æ•°
            try:
                file_descriptors = self.process.num_fds()
            except (AttributeError, psutil.AccessDenied):
                # Windowsã¾ãŸã¯ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒãªã„å ´åˆ
                file_descriptors = 0
            
            snapshot = MemorySnapshot(
                timestamp=datetime.now(),
                process_memory_mb=process_memory_mb,
                system_memory_percent=system_memory_percent,
                tracemalloc_current_mb=tracemalloc_current_mb,
                tracemalloc_peak_mb=tracemalloc_peak_mb,
                gc_objects_count=gc_objects_count,
                thread_count=thread_count,
                file_descriptors=file_descriptors,
                context=context
            )
            
            # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            self.snapshots.append(snapshot)
            
            # æœ€å¤§æ•°ã‚’è¶…ãˆãŸå ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
            if len(self.snapshots) > self.max_snapshots:
                self.snapshots = self.snapshots[-self.max_snapshots:]
            
            logger.debug(f"ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—: {process_memory_mb:.1f}MB ({context})")
            return snapshot
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—ã«å¤±æ•—: {e}")
            raise

    def start_monitoring(self, interval: float = 5.0) -> None:
        """
        ç¶™ç¶šçš„ãªãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’é–‹å§‹

        Args:
            interval: ç›£è¦–é–“éš”ï¼ˆç§’ï¼‰
        """
        if self.monitoring_active:
            logger.warning("ãƒ¡ãƒ¢ãƒªç›£è¦–ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
            return
        
        self.monitoring_interval = interval
        self.monitoring_active = True
        
        def monitor_loop():
            logger.info(f"ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼ˆé–“éš”: {interval}ç§’ï¼‰")
            
            while self.monitoring_active:
                try:
                    snapshot = self.take_snapshot("ç›£è¦–")
                    
                    # é–¾å€¤ãƒã‚§ãƒƒã‚¯
                    self._check_thresholds(snapshot)
                    
                    time.sleep(interval)
                    
                except Exception as e:
                    logger.error(f"ãƒ¡ãƒ¢ãƒªç›£è¦–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    time.sleep(interval)
            
            logger.info("ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        self.monitoring_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitoring_thread.start()

    def stop_monitoring(self) -> None:
        """ç¶™ç¶šçš„ãªãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’åœæ­¢"""
        if not self.monitoring_active:
            return
        
        self.monitoring_active = False
        
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_thread.join(timeout=10)
        
        logger.info("ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")

    def detect_memory_leaks(self, duration_minutes: int = 5) -> List[MemoryLeak]:
        """
        ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º

        Args:
            duration_minutes: æ¤œå‡ºæœŸé–“ï¼ˆåˆ†ï¼‰

        Returns:
            æ¤œå‡ºã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºã‚’é–‹å§‹ï¼ˆæœŸé–“: {duration_minutes}åˆ†ï¼‰")
        
        leaks = []
        cutoff_time = datetime.now() - timedelta(minutes=duration_minutes)
        
        # æŒ‡å®šæœŸé–“å†…ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        recent_snapshots = [
            s for s in self.snapshots
            if s.timestamp >= cutoff_time
        ]
        
        if len(recent_snapshots) < 2:
            logger.warning("ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºã«ååˆ†ãªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return leaks
        
        # æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
        recent_snapshots.sort(key=lambda x: x.timestamp)
        
        # ãƒªãƒ¼ã‚¯æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
        window_size = min(10, len(recent_snapshots) // 2)  # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        
        for i in range(len(recent_snapshots) - window_size):
            start_window = recent_snapshots[i:i + window_size]
            end_window = recent_snapshots[i + window_size:]
            
            if len(end_window) < window_size:
                continue
            
            end_window = end_window[:window_size]
            
            # å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è¨ˆç®—
            start_avg_memory = sum(s.process_memory_mb for s in start_window) / len(start_window)
            end_avg_memory = sum(s.process_memory_mb for s in end_window) / len(end_window)
            
            # æ™‚é–“å·®ã‚’è¨ˆç®—
            time_diff = (end_window[-1].timestamp - start_window[0].timestamp).total_seconds()
            
            if time_diff <= 0:
                continue
            
            # ãƒªãƒ¼ã‚¯ç‡ã‚’è¨ˆç®—
            memory_diff = end_avg_memory - start_avg_memory
            leak_rate = memory_diff / time_diff
            
            # ãƒªãƒ¼ã‚¯åˆ¤å®š
            if leak_rate > self.thresholds.leak_rate_mb_per_sec:
                severity = self._determine_leak_severity(leak_rate, memory_diff)
                
                # ãƒˆãƒƒãƒ—ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—
                top_allocations = self._get_top_allocations()
                
                # åˆ†ææƒ…å ±ã‚’ç”Ÿæˆ
                analysis = self._analyze_memory_leak(
                    start_window[0], end_window[-1], leak_rate, memory_diff
                )
                
                leak = MemoryLeak(
                    start_snapshot=start_window[0],
                    end_snapshot=end_window[-1],
                    leak_rate_mb_per_sec=leak_rate,
                    total_leaked_mb=memory_diff,
                    duration_seconds=time_diff,
                    severity=severity,
                    analysis=analysis,
                    top_allocations=top_allocations
                )
                
                leaks.append(leak)
                
                logger.warning(
                    f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º: {leak_rate:.3f}MB/ç§’ "
                    f"(ç·é‡: {memory_diff:.1f}MB, é‡è¦åº¦: {severity})"
                )
        
        # ãƒªãƒ¼ã‚¯ã‚’ä¿å­˜
        if leaks:
            self._save_leaks(leaks)
        
        logger.info(f"{len(leaks)}å€‹ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
        return leaks

    def profile_function(self, func: Callable, *args, **kwargs) -> Tuple[Any, MemorySnapshot, MemorySnapshot]:
        """
        é–¢æ•°å®Ÿè¡Œæ™‚ã®ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

        Args:
            func: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å¯¾è±¡ã®é–¢æ•°
            *args: é–¢æ•°ã®å¼•æ•°
            **kwargs: å‡½æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°

        Returns:
            (é–¢æ•°ã®æˆ»ã‚Šå€¤, å®Ÿè¡Œå‰ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ, å®Ÿè¡Œå¾Œã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ)
        """
        logger.info(f"é–¢æ•°ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°é–‹å§‹: {func.__name__}")
        
        # å®Ÿè¡Œå‰ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        gc.collect()  # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        before_snapshot = self.take_snapshot(f"å®Ÿè¡Œå‰: {func.__name__}")
        
        try:
            # é–¢æ•°å®Ÿè¡Œ
            result = func(*args, **kwargs)
            
            # å®Ÿè¡Œå¾Œã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
            after_snapshot = self.take_snapshot(f"å®Ÿè¡Œå¾Œ: {func.__name__}")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¤‰åŒ–ã‚’ãƒ­ã‚°å‡ºåŠ›
            memory_diff = after_snapshot.process_memory_mb - before_snapshot.process_memory_mb
            tracemalloc_diff = after_snapshot.tracemalloc_current_mb - before_snapshot.tracemalloc_current_mb
            
            logger.info(
                f"é–¢æ•°ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Œäº†: {func.__name__} "
                f"(ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªå¤‰åŒ–: {memory_diff:+.1f}MB, "
                f"tracemallocå¤‰åŒ–: {tracemalloc_diff:+.1f}MB)"
            )
            
            return result, before_snapshot, after_snapshot
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
            error_snapshot = self.take_snapshot(f"ã‚¨ãƒ©ãƒ¼æ™‚: {func.__name__}")
            logger.error(f"é–¢æ•°å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {func.__name__}: {e}")
            raise

    def generate_memory_report(self, hours: int = 24) -> Dict[str, Any]:
        """
        ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            hours: ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡æœŸé–“ï¼ˆæ™‚é–“ï¼‰

        Returns:
            ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆ
        """
        logger.info(f"éå»{hours}æ™‚é–“ã®ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­")
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        # æœŸé–“å†…ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—
        recent_snapshots = [
            s for s in self.snapshots
            if s.timestamp >= cutoff_time
        ]
        
        if not recent_snapshots:
            logger.warning("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return {
                'period_hours': hours,
                'error': 'ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™',
                'snapshots_count': 0
            }
        
        # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
        memory_values = [s.process_memory_mb for s in recent_snapshots]
        system_memory_values = [s.system_memory_percent for s in recent_snapshots]
        tracemalloc_values = [s.tracemalloc_current_mb for s in recent_snapshots]
        gc_objects_values = [s.gc_objects_count for s in recent_snapshots]
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º
        leaks = self.detect_memory_leaks(duration_minutes=hours * 60)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            'period_hours': hours,
            'generated_at': datetime.now().isoformat(),
            'snapshots_count': len(recent_snapshots),
            
            'process_memory': {
                'current_mb': memory_values[-1] if memory_values else 0,
                'min_mb': min(memory_values) if memory_values else 0,
                'max_mb': max(memory_values) if memory_values else 0,
                'avg_mb': sum(memory_values) / len(memory_values) if memory_values else 0,
                'trend': self._calculate_trend(memory_values)
            },
            
            'system_memory': {
                'current_percent': system_memory_values[-1] if system_memory_values else 0,
                'min_percent': min(system_memory_values) if system_memory_values else 0,
                'max_percent': max(system_memory_values) if system_memory_values else 0,
                'avg_percent': sum(system_memory_values) / len(system_memory_values) if system_memory_values else 0
            },
            
            'tracemalloc': {
                'current_mb': tracemalloc_values[-1] if tracemalloc_values else 0,
                'min_mb': min(tracemalloc_values) if tracemalloc_values else 0,
                'max_mb': max(tracemalloc_values) if tracemalloc_values else 0,
                'avg_mb': sum(tracemalloc_values) / len(tracemalloc_values) if tracemalloc_values else 0,
                'peak_mb': max(s.tracemalloc_peak_mb for s in recent_snapshots) if recent_snapshots else 0
            },
            
            'gc_objects': {
                'current_count': gc_objects_values[-1] if gc_objects_values else 0,
                'min_count': min(gc_objects_values) if gc_objects_values else 0,
                'max_count': max(gc_objects_values) if gc_objects_values else 0,
                'avg_count': sum(gc_objects_values) / len(gc_objects_values) if gc_objects_values else 0
            },
            
            'memory_leaks': {
                'detected_count': len(leaks),
                'critical_count': len([l for l in leaks if l.severity == 'CRITICAL']),
                'high_count': len([l for l in leaks if l.severity == 'HIGH']),
                'total_leaked_mb': sum(l.total_leaked_mb for l in leaks)
            },
            
            'thresholds_exceeded': self._check_threshold_violations(recent_snapshots),
            
            'recommendations': self._generate_recommendations(recent_snapshots, leaks)
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        report_file = self.reports_dir / f"memory_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {report_file}")
        return report

    def _check_thresholds(self, snapshot: MemorySnapshot) -> None:
        """é–¾å€¤ãƒã‚§ãƒƒã‚¯"""
        alerts = []
        
        if snapshot.process_memory_mb > self.thresholds.process_memory_mb:
            alerts.append(
                f"ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…é: {snapshot.process_memory_mb:.1f}MB "
                f"(é–¾å€¤: {self.thresholds.process_memory_mb}MB)"
            )
        
        if snapshot.system_memory_percent > self.thresholds.system_memory_percent:
            alerts.append(
                f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé–¾å€¤ã‚’è¶…é: {snapshot.system_memory_percent:.1f}% "
                f"(é–¾å€¤: {self.thresholds.system_memory_percent}%)"
            )
        
        for alert in alerts:
            logger.warning(alert)

    def _determine_leak_severity(self, leak_rate: float, total_leaked: float) -> str:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®é‡è¦åº¦ã‚’åˆ¤å®š"""
        if leak_rate > 10.0 or total_leaked > 100.0:
            return 'CRITICAL'
        elif leak_rate > 5.0 or total_leaked > 50.0:
            return 'HIGH'
        elif leak_rate > 2.0 or total_leaked > 20.0:
            return 'MEDIUM'
        else:
            return 'LOW'

    def _get_top_allocations(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ãƒˆãƒƒãƒ—ãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’å–å¾—"""
        try:
            snapshot = tracemalloc.take_snapshot()
            top_stats = snapshot.statistics('lineno')
            
            allocations = []
            for stat in top_stats[:limit]:
                allocations.append({
                    'size_mb': stat.size / 1024 / 1024,
                    'count': stat.count,
                    'filename': stat.traceback.format()[0] if stat.traceback.format() else 'unknown',
                })
            
            return allocations
        except Exception as e:
            logger.error(f"ãƒˆãƒƒãƒ—ã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³å–å¾—ã«å¤±æ•—: {e}")
            return []

    def _analyze_memory_leak(self, start: MemorySnapshot, end: MemorySnapshot, 
                           leak_rate: float, total_leaked: float) -> str:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®åˆ†æ"""
        analysis_parts = []
        
        # åŸºæœ¬æƒ…å ±
        duration = (end.timestamp - start.timestamp).total_seconds()
        analysis_parts.append(f"{duration:.0f}ç§’é–“ã§{total_leaked:.1f}MBã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯")
        
        # GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ã®å¤‰åŒ–
        gc_diff = end.gc_objects_count - start.gc_objects_count
        if gc_diff > 0:
            gc_rate = gc_diff / duration
            analysis_parts.append(f"GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ãŒ{gc_diff}å€‹å¢—åŠ ï¼ˆ{gc_rate:.1f}å€‹/ç§’ï¼‰")
        
        # ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ã®å¤‰åŒ–
        thread_diff = end.thread_count - start.thread_count
        if thread_diff > 0:
            analysis_parts.append(f"ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ãŒ{thread_diff}å€‹å¢—åŠ ")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿ã®å¤‰åŒ–
        fd_diff = end.file_descriptors - start.file_descriptors
        if fd_diff > 0:
            analysis_parts.append(f"ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚¿ãŒ{fd_diff}å€‹å¢—åŠ ")
        
        return "ã€".join(analysis_parts)

    def _calculate_trend(self, values: List[float]) -> str:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        if len(values) < 2:
            return "ä¸æ˜"
        
        # ç·šå½¢å›å¸°ã®å‚¾ãã‚’è¨ˆç®—
        n = len(values)
        x = list(range(n))
        
        sum_x = sum(x)
        sum_y = sum(values)
        sum_xy = sum(x[i] * values[i] for i in range(n))
        sum_x2 = sum(x[i] ** 2 for i in range(n))
        
        if n * sum_x2 - sum_x ** 2 == 0:
            return "å®‰å®š"
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)
        
        if slope > 0.1:
            return "å¢—åŠ "
        elif slope < -0.1:
            return "æ¸›å°‘"
        else:
            return "å®‰å®š"

    def _check_threshold_violations(self, snapshots: List[MemorySnapshot]) -> Dict[str, int]:
        """é–¾å€¤é•åã‚’ãƒã‚§ãƒƒã‚¯"""
        violations = {
            'process_memory': 0,
            'system_memory': 0,
            'total': 0
        }
        
        for snapshot in snapshots:
            if snapshot.process_memory_mb > self.thresholds.process_memory_mb:
                violations['process_memory'] += 1
                violations['total'] += 1
            
            if snapshot.system_memory_percent > self.thresholds.system_memory_percent:
                violations['system_memory'] += 1
                violations['total'] += 1
        
        return violations

    def _generate_recommendations(self, snapshots: List[MemorySnapshot], 
                                leaks: List[MemoryLeak]) -> List[str]:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []
        
        if not snapshots:
            return recommendations
        
        # æœ€æ–°ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ
        latest = snapshots[-1]
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„å ´åˆ
        if latest.process_memory_mb > self.thresholds.process_memory_mb:
            recommendations.append(
                f"ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé«˜ã„ã§ã™ï¼ˆ{latest.process_memory_mb:.1f}MBï¼‰ã€‚"
                "ä¸è¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å‰Šé™¤ã‚„ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆ
        if leaks:
            critical_leaks = [l for l in leaks if l.severity in ['HIGH', 'CRITICAL']]
            if critical_leaks:
                recommendations.append(
                    f"{len(critical_leaks)}å€‹ã®é‡è¦ãªãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"
                    "ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ãƒ¡ãƒ¢ãƒªç®¡ç†ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚"
                )
        
        # GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ãŒå¤šã„å ´åˆ
        if latest.gc_objects_count > 100000:
            recommendations.append(
                f"GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ãŒå¤šã„ã§ã™ï¼ˆ{latest.gc_objects_count:,}å€‹ï¼‰ã€‚"
                "å¾ªç’°å‚ç…§ã‚„ä¸è¦ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‚ç…§ã®ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
            )
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„å ´åˆ
        if latest.system_memory_percent > 90:
            recommendations.append(
                f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„ã§ã™ï¼ˆ{latest.system_memory_percent:.1f}%ï¼‰ã€‚"
                "ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã®çµ‚äº†ã‚„ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºèªã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )
        
        return recommendations

    def _save_snapshots(self) -> None:
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜"""
        try:
            data = [s.to_dict() for s in self.snapshots]
            
            with open(self.snapshots_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"{len(self.snapshots)}å€‹ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ã«å¤±æ•—: {e}")

    def _load_snapshots(self) -> None:
        """ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿"""
        if not self.snapshots_file.exists():
            return
        
        try:
            with open(self.snapshots_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.snapshots = []
            for item in data:
                item['timestamp'] = datetime.fromisoformat(item['timestamp'])
                self.snapshots.append(MemorySnapshot(**item))
            
            logger.info(f"{len(self.snapshots)}å€‹ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆèª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")

    def _save_leaks(self, leaks: List[MemoryLeak]) -> None:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’ä¿å­˜"""
        try:
            # æ—¢å­˜ã®ãƒªãƒ¼ã‚¯ã‚’èª­ã¿è¾¼ã¿
            existing_leaks = self._load_leaks()
            existing_leaks.extend(leaks)
            
            # å¤ã„ãƒªãƒ¼ã‚¯ã‚’å‰Šé™¤ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
            cutoff_time = datetime.now() - timedelta(days=7)
            existing_leaks = [
                l for l in existing_leaks
                if l.start_snapshot.timestamp >= cutoff_time
            ]
            
            # JSONå½¢å¼ã§ä¿å­˜
            data = []
            for leak in existing_leaks:
                leak_dict = {
                    'start_snapshot': leak.start_snapshot.to_dict(),
                    'end_snapshot': leak.end_snapshot.to_dict(),
                    'leak_rate_mb_per_sec': leak.leak_rate_mb_per_sec,
                    'total_leaked_mb': leak.total_leaked_mb,
                    'duration_seconds': leak.duration_seconds,
                    'severity': leak.severity,
                    'analysis': leak.analysis,
                    'top_allocations': leak.top_allocations
                }
                data.append(leak_dict)
            
            with open(self.leaks_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"{len(existing_leaks)}å€‹ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ä¿å­˜ã«å¤±æ•—: {e}")

    def _load_leaks(self) -> List[MemoryLeak]:
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’èª­ã¿è¾¼ã¿"""
        if not self.leaks_file.exists():
            return []
        
        try:
            with open(self.leaks_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            leaks = []
            for item in data:
                # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å¾©å…ƒ
                start_dict = item['start_snapshot']
                start_dict['timestamp'] = datetime.fromisoformat(start_dict['timestamp'])
                start_snapshot = MemorySnapshot(**start_dict)
                
                end_dict = item['end_snapshot']
                end_dict['timestamp'] = datetime.fromisoformat(end_dict['timestamp'])
                end_snapshot = MemorySnapshot(**end_dict)
                
                leak = MemoryLeak(
                    start_snapshot=start_snapshot,
                    end_snapshot=end_snapshot,
                    leak_rate_mb_per_sec=item['leak_rate_mb_per_sec'],
                    total_leaked_mb=item['total_leaked_mb'],
                    duration_seconds=item['duration_seconds'],
                    severity=item['severity'],
                    analysis=item['analysis'],
                    top_allocations=item['top_allocations']
                )
                leaks.append(leak)
            
            return leaks
            
        except Exception as e:
            logger.error(f"ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            return []

    def cleanup(self) -> None:
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.stop_monitoring()
        self._save_snapshots()
        
        if tracemalloc.is_tracing():
            tracemalloc.stop()
            logger.info("tracemallocç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument(
        '--monitor',
        type=int,
        metavar='SECONDS',
        help='æŒ‡å®šç§’æ•°é–“ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’å®Ÿè¡Œ'
    )
    parser.add_argument(
        '--detect-leaks',
        type=int,
        metavar='MINUTES',
        default=5,
        help='æŒ‡å®šåˆ†æ•°é–“ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º'
    )
    parser.add_argument(
        '--generate-report',
        type=int,
        metavar='HOURS',
        default=24,
        help='æŒ‡å®šæ™‚é–“ã®ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ'
    )
    parser.add_argument(
        '--snapshot',
        action='store_true',
        help='ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’å–å¾—'
    )
    parser.add_argument(
        '--data-dir',
        default='logs/performance/memory',
        help='ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª'
    )
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›'
    )
    
    args = parser.parse_args()
    
    # ãƒ­ã‚°è¨­å®š
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('logs/memory_profiler.log', encoding='utf-8')
        ]
    )
    
    profiler = MemoryProfiler(args.data_dir)
    
    try:
        if args.snapshot:
            # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—
            snapshot = profiler.take_snapshot("æ‰‹å‹•å®Ÿè¡Œ")
            print(f"ğŸ“¸ ãƒ¡ãƒ¢ãƒªã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ:")
            print(f"  ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒª: {snapshot.process_memory_mb:.1f}MB")
            print(f"  ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {snapshot.system_memory_percent:.1f}%")
            print(f"  tracemalloc: {snapshot.tracemalloc_current_mb:.1f}MB (ãƒ”ãƒ¼ã‚¯: {snapshot.tracemalloc_peak_mb:.1f}MB)")
            print(f"  GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {snapshot.gc_objects_count:,}å€‹")
            print(f"  ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {snapshot.thread_count}")
        
        elif args.monitor:
            # ãƒ¡ãƒ¢ãƒªç›£è¦–
            print(f"ğŸ” {args.monitor}ç§’é–“ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’é–‹å§‹...")
            profiler.start_monitoring(interval=1.0)
            time.sleep(args.monitor)
            profiler.stop_monitoring()
            
            # ç›£è¦–çµæœã®è¡¨ç¤º
            if profiler.snapshots:
                latest = profiler.snapshots[-1]
                print(f"ğŸ“Š ç›£è¦–çµæœ:")
                print(f"  æœ€çµ‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {latest.process_memory_mb:.1f}MB")
                print(f"  ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°: {len(profiler.snapshots)}")
        
        elif args.detect_leaks:
            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡º
            leaks = profiler.detect_memory_leaks(duration_minutes=args.detect_leaks)
            
            if leaks:
                print(f"âš ï¸  {len(leaks)}å€‹ã®ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’æ¤œå‡º:")
                for leak in leaks:
                    print(f"  - ãƒªãƒ¼ã‚¯ç‡: {leak.leak_rate_mb_per_sec:.3f}MB/ç§’")
                    print(f"    ç·ãƒªãƒ¼ã‚¯é‡: {leak.total_leaked_mb:.1f}MB")
                    print(f"    é‡è¦åº¦: {leak.severity}")
                    print(f"    åˆ†æ: {leak.analysis}")
                    print()
            else:
                print("âœ… ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        elif args.generate_report:
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = profiler.generate_memory_report(hours=args.generate_report)
            
            print(f"ğŸ“‹ ãƒ¡ãƒ¢ãƒªãƒ¬ãƒãƒ¼ãƒˆ ({report['period_hours']}æ™‚é–“)")
            print(f"ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆæ•°: {report['snapshots_count']}")
            
            if 'error' not in report:
                pm = report['process_memory']
                print(f"\nğŸ’¾ ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒª:")
                print(f"  ç¾åœ¨: {pm['current_mb']:.1f}MB")
                print(f"  æœ€å°-æœ€å¤§: {pm['min_mb']:.1f}-{pm['max_mb']:.1f}MB")
                print(f"  å¹³å‡: {pm['avg_mb']:.1f}MB")
                print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰: {pm['trend']}")
                
                ml = report['memory_leaks']
                print(f"\nğŸš¨ ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯:")
                print(f"  æ¤œå‡ºæ•°: {ml['detected_count']}")
                print(f"  é‡è¦: {ml['critical_count']}")
                print(f"  ç·ãƒªãƒ¼ã‚¯é‡: {ml['total_leaked_mb']:.1f}MB")
                
                if report['recommendations']:
                    print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
                    for rec in report['recommendations']:
                        print(f"  - {rec}")
            else:
                print(f"âŒ {report['error']}")
        
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: åŸºæœ¬æƒ…å ±è¡¨ç¤º
            snapshot = profiler.take_snapshot("åŸºæœ¬æƒ…å ±")
            print(f"ğŸ–¥ï¸  ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼")
            print(f"ãƒ—ãƒ­ã‚»ã‚¹ãƒ¡ãƒ¢ãƒª: {snapshot.process_memory_mb:.1f}MB")
            print(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {snapshot.system_memory_percent:.1f}%")
            print(f"GCã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°: {snapshot.gc_objects_count:,}å€‹")
            print(f"\nä½¿ç”¨æ–¹æ³•:")
            print(f"  --monitor SECONDS     : ãƒ¡ãƒ¢ãƒªç›£è¦–")
            print(f"  --detect-leaks MINUTES: ãƒªãƒ¼ã‚¯æ¤œå‡º")
            print(f"  --generate-report HOURS: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            print(f"  --snapshot            : ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå–å¾—")
    
    except KeyboardInterrupt:
        logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return 1
    finally:
        profiler.cleanup()
    
    return 0


if __name__ == "__main__":
    exit(main())